#' Retrieve the latest message from the chat history of a Generative AI model
#'
#' This function fetches the most recent message in the chat history of a Generative AI model.
#'
#' @param model.parameter A character vector containing essential information about the
#' Generative AI service provider, model, version, API key, and proxy status.
#' @param history A list containing all messages exchanged between the user and the model in a chat session.
#'
#' @return If successful, the function returns the latest message in the chat history. In case of
#' incorrect input format, the function halts execution and provides an error message.
#'
#' @details Providing accurate and valid information for each parameter is crucial for successful
#' text generation by the Generative AI model. This function modifies the chat history. If any
#' parameter is incorrect, the function responds with an error message based on the API feedback.
#' To view all supported Generative AI models, use the function \code{available.models}.
#' Additionally, utilize \code{chat.setup} to set up a chat history.
#'
#' @examples
#' \dontrun{
#'  # Get available models
#'  models = available.models()
#'
#'  # Connect to the model, replace API_KEY with your api key
#'  google.model = connect.genai("google",
#'                               models$google$model[1],
#'                               models$google$version[1],
#'                               "API_KEY",
#'                               FALSE)
#'
#'  # Connect to the model, replace API_KEY with your api key
#'  openai.model = connect.genai("openai",
#'                               models$openai$model[1],
#'                               models$openai$version[1],
#'                               "API_KEY",
#'                               FALSE)
#'  # Setup an empty chat history
#'  google.history = chat.steup(google.model)
#'  openai.history = chat.steup(openai.model)
#'
#'  # Start chat
#'  temperature = 0.9
#'  prompt = "Write a story about a magic backpack in about 100 words."
#'  google.history = chat(google.model,
#'                        temperature,
#'                        google.history,
#'                        prompt)
#'
#'  # Get the most recent message generated by the model
#'  cat(chat.recent(google.model, google.history))
#'
#'  openai.history = chat(openai.model,
#'                        temperature,
#'                        openai.history,
#'                        prompt)
#'
#'  # Get the most recent message generated by the model
#'  cat(chat.recent(openai.model, openai.history))
#'
#'  prompt = "What is the word count of the story you just wrote?"
#'  google.history = chat(google.model,
#'                        temperature,
#'                        google.history,
#'                        prompt)
#'
#'  # Get the most recent message generated by the model
#'  cat(chat.recent(google.model, google.history))
#'
#'  openai.history = chat(openai.model,
#'                        temperature,
#'                        openai.history,
#'                        prompt)
#'
#'  # Get the most recent message generated by the model
#'  cat(chat.recent(openai.model, openai.history))
#' }
#'
#' @export
chat.recent = function(model.parameter, history) {
  switch (model.parameter["provider"],
          google = {
            return (history$contents[[length(history$contents)]]$parts$text)
          },
          openai = {
            return (history$messages[[length(history$messages)]]$content)
          })
  stop("Invalid function argument(s).")
}
