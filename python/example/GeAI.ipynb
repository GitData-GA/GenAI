{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOliqv606BTqK5z2pvV3uPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitData-GA/GenAI/blob/gh-pages/python/example/GeAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install GeAI"
      ],
      "metadata": {
        "id": "8p9WjDM8yVxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f485cb-f90d-4613-8bb0-73aff81bbbf4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GeAI==0.1.8 in /usr/local/lib/python3.10/dist-packages (0.1.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import GeAI as ga"
      ],
      "metadata": {
        "id": "nWB3pvroBi5W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = ga.available_models()\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqumLZAvKHuC",
        "outputId": "03835173-6929-41bf-add4-af645a44f0e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'google': {'version': ['v1', 'v1beta'],\n",
              "  'model': ['gemini-pro', 'gemini-pro-vision']},\n",
              " 'openai': {'version': ['v1'],\n",
              "  'model': ['gpt-3.5-turbo',\n",
              "   'gpt-3.5-turbo-16k',\n",
              "   'gpt-4',\n",
              "   'gpt-4-32k',\n",
              "   'gpt-4-vision-preview']}}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_model = ga.connect('google',\n",
        "                          models['google']['model'][0],\n",
        "                          models['google']['version'][0],\n",
        "                          'API_KEY',\n",
        "                          proxy = False)\n",
        "google_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkToOHVWmnuG",
        "outputId": "852eef03-66af-4424-fafd-63815a52a277"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'provider': 'google',\n",
              " 'model': 'gemini-pro',\n",
              " 'version': 'v1',\n",
              " 'api': 'AIzaSyDrHj8tg968vFkz8kBkH3TC1UBhM7inUw0',\n",
              " 'proxy': False}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_model = ga.connect('openai',\n",
        "                          models['openai']['model'][0],\n",
        "                          models['openai']['version'][0],\n",
        "                          'API_KEY',\n",
        "                          proxy = False)\n",
        "openai_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuSfGlIZkWwY",
        "outputId": "e78f7ab8-e875-4bf1-914c-abe4cd7d6a8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'provider': 'openai',\n",
              " 'model': 'gpt-3.5-turbo',\n",
              " 'version': 'v1',\n",
              " 'api': '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',\n",
              " 'proxy': False}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_text = ga.txt(google_model,\n",
        "                     0.9,\n",
        "                    \"Hello\")\n",
        "print(google_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayHA6zEUgndd",
        "outputId": "ca1425e8-ec35-4bc2-e373-33dffdd6e212"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello there! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_text = ga.txt(openai_model,\n",
        "                     0.9,\n",
        "                    \"Hello\")\n",
        "print(openai_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYyJQqjPiHsQ",
        "outputId": "cadb8731-02da-44f9-a6cd-590d47acddfe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 0.9\n",
        "prompt = \"\"\"\n",
        "def foo(n):\n",
        "    if n <= 0:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return foo(n - 1) + foo(n - 2)\n",
        "\"\"\"\n",
        "\n",
        "code_explanation = ga.txt.explain_code(google_model,\n",
        "                                       0.9,\n",
        "                                       prompt)\n",
        "print(code_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KjiuPF7iUlO",
        "outputId": "f7c82d2a-2d3f-4c0b-eaf0-29622e3bf130"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided Python code defines a recursive function called `foo` that calculates the nth Fibonacci number.\n",
            "\n",
            "Here's how the code works:\n",
            "\n",
            "1. The `foo` function takes one argument, `n`, which represents the position of the Fibonacci number you want to find.\n",
            "\n",
            "2. The function uses the following three cases to calculate the Fibonacci number:\n",
            "\n",
            "   - If `n` is less than or equal to 0, it returns 0. This is the base case for the recursive function.\n",
            "   - If `n` is equal to 1, it returns 1. This is also a base case, as the first Fibonacci number is 1.\n",
            "   - Otherwise, it recursively calls itself twice: `foo(n - 1)` and `foo(n - 2)`. It then adds the results of these two recursive calls and returns that value.\n",
            "\n",
            "To calculate the nth Fibonacci number using this function, you would call `foo(n)`, where `n` is the position of the Fibonacci number you want to find. For example, to calculate the 5th Fibonacci number, you would call `foo(5)`.\n",
            "\n",
            "Here's an example of how the recursive calls work:\n",
            "\n",
            "To calculate `foo(5)`, the function would make the following calls:\n",
            "\n",
            "- `foo(5)`\n",
            "- `foo(4)`\n",
            "- `foo(3)`\n",
            "- `foo(2)`\n",
            "- `foo(1)`\n",
            "- `foo(0)`\n",
            "\n",
            "At this point, the base cases are reached, and the function starts returning values:\n",
            "\n",
            "- `foo(0)` returns 0.\n",
            "- `foo(1)` returns 1.\n",
            "- `foo(2)` returns `foo(1)` + `foo(0)` = 1 + 0 = 1.\n",
            "- `foo(3)` returns `foo(2)` + `foo(1)` = 1 + 1 = 2.\n",
            "- `foo(4)` returns `foo(3)` + `foo(2)` = 2 + 1 = 3.\n",
            "- `foo(5)` returns `foo(4)` + `foo(3)` = 3 + 2 = 5.\n",
            "\n",
            "So, `foo(5)` returns 5, which is the 5th Fibonacci number.\n",
            "\n",
            "This code showcases the concept of recursion, where a function calls itself to solve a smaller version of the same problem. It also illustrates how Fibonacci numbers are calculated using a recursive approach.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_explanation = ga.txt.explain_code(openai_model,\n",
        "                                       0.9,\n",
        "                                       prompt)\n",
        "print(code_explanation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea1FMin8K8h2",
        "outputId": "97f6194e-d2fb-4a8d-da3d-77201b4fefac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided code is a Python function called \"foo\" that calculates the nth number in the Fibonacci sequence recursively. \n",
            "\n",
            "The Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones, usually starting with 0 and 1. In this code, the function calculates the Fibonacci number using recursion.\n",
            "\n",
            "Here's a breakdown of the code:\n",
            "\n",
            "- The function \"foo\" takes an integer argument \"n\" which represents the index of the Fibonacci number to be calculated.\n",
            "- Inside the function, it first checks if \"n\" is less than or equal to 0. If it is, it returns 0, as there are no Fibonacci numbers for negative indexes.\n",
            "- Then, it checks if \"n\" is equal to 1. If it is, it returns 1, as the first Fibonacci number is 1.\n",
            "- If neither of the above conditions is true, it recursively calls the \"foo\" function passing \"n-1\" and \"n-2\" as arguments, and returns the sum of the two recursive function calls.\n",
            "- In each recursive call, the \"foo\" function is called for smaller values of \"n\" until the base cases (n <= 0 or n == 1) are met.\n",
            "\n",
            "To use this code, you can call the \"foo\" function and pass the desired index of the Fibonacci number you want to calculate. For example, calling \"foo(5)\" would return the 5th Fibonacci number, which is 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 0.9\n",
        "prompt = \"\"\"\n",
        "def foo(n):\n",
        "    if n <= 0:\n",
        "        return 0\n",
        "    elif n == 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return foo(n - 1) + foo(n - 2)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ww_46q6HKa7-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_optimization = ga.txt.optimize_code(google_model,\n",
        "                                         0.9,\n",
        "                                         prompt,\n",
        "                                         'Improve the runtime.')\n",
        "print(code_optimization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXnqX4WxKZTu",
        "outputId": "18575e17-5443-472e-f3cd-02b72c106bf6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided code calculates the nth Fibonacci number using a recursive approach. However, this recursive implementation can be inefficient for large values of n due to redundant calculations. To optimize the runtime, you can use a dynamic programming approach that stores previously calculated Fibonacci numbers to avoid recomputing them.\n",
            "\n",
            "Here's the optimized Python code:\n",
            "\n",
            "```python\n",
            "def foo(n):\n",
            "    fib_sequence = [0, 1]  # Initialize the first two Fibonacci numbers\n",
            "    while len(fib_sequence) <= n:\n",
            "        next_number = fib_sequence[-1] + fib_sequence[-2]\n",
            "        fib_sequence.append(next_number)\n",
            "    return fib_sequence[n]\n",
            "```\n",
            "\n",
            "This code uses a loop to iteratively compute the Fibonacci sequence up to the desired value of n. It stores the computed Fibonacci numbers in the fib_sequence list, and when it needs to find the nth Fibonacci number, it simply returns the corresponding value from the list. This approach avoids the redundant calculations of the recursive implementation, resulting in a significant improvement in runtime performance, especially for large values of n.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_optimization = ga.txt.optimize_code(openai_model,\n",
        "                                         0.9,\n",
        "                                         prompt,\n",
        "                                         'Improve the runtime.')\n",
        "print(code_optimization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvwyDlTrXx2X",
        "outputId": "e1ff78e1-dab4-4733-ee50-221ae53acbeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided code is implementing a recursive function to calculate the nth Fibonacci number. However, recursion can be inefficient for larger values of n, resulting in exponential time complexity. To optimize the code and improve runtime, let's modify it to use dynamic programming and memoization.\n",
            "\n",
            "Here's the optimized code:\n",
            "\n",
            "# Code starts #\n",
            "\n",
            "def foo(n, memo):\n",
            "    if n <= 0:\n",
            "        return 0\n",
            "    elif n == 1:\n",
            "        return 1\n",
            "    elif memo[n] != 0:\n",
            "        return memo[n]\n",
            "    else:\n",
            "        memo[n] = foo(n - 1, memo) + foo(n - 2, memo)\n",
            "        return memo[n]\n",
            "\n",
            "n = 10\n",
            "memo = [0] * (n + 1)\n",
            "result = foo(n, memo)\n",
            "print(result)\n",
            "\n",
            "# Code ends #\n",
            "\n",
            "In the optimized code, we introduce an additional parameter called memo, which is used to store the calculated Fibonacci numbers. The memo list is initialized with zeros. As the function calculates each Fibonacci number, it checks if the result is already present in the memo. If so, it directly returns the value from the memo instead of recalculating.\n",
            "\n",
            "This approach significantly reduces the number of function calls and allows for much faster computation of large Fibonacci numbers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = 0.9\n",
        "prompt = \"\"\"Yesterday, I will buy a book for my younger sister as his birthday gift.\n",
        "         They were very happen when seeing this gift earlier today.\"\"\"\n",
        "\n",
        "correct_text = ga.txt.fix_grammar(google_model,\n",
        "                                  0.9,\n",
        "                                  prompt)\n",
        "print(correct_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhSAvlNeSnaL",
        "outputId": "3da88dd2-2899-42b0-dc1c-c3d97d3b1c9c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yesterday, I bought a book for my younger sister as her birthday gift.\n",
            "She was very happy when she saw the gift earlier today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_text = ga.txt.fix_grammar(openai_model,\n",
        "                                  0.9,\n",
        "                                  prompt)\n",
        "print(correct_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb4A-gY-S9iD",
        "outputId": "505bd379-40aa-4c54-aa50-69b07863abde"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yesterday, I bought a book for my younger sister as her birthday gift. They were very happy when they saw this gift earlier today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_vision_model = ga.connect('google',\n",
        "                                 'gemini-pro-vision',\n",
        "                                 'v1beta',\n",
        "                                 'API_KEY',\n",
        "                                 False)\n",
        "openai_vision_model = ga.connect('openai',\n",
        "                                 'gpt-4-vision-preview',\n",
        "                                 'v1',\n",
        "                                 'API_KEY',\n",
        "                                 False)"
      ],
      "metadata": {
        "id": "_TQlXxqwUFqi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is this picture?\"\n",
        "image_path = \"https://storage.googleapis.com/generativeai-downloads/images/scones.jpg\"\n",
        "image_description = ga.txt.image(google_vision_model,\n",
        "                                 0.9,\n",
        "                                 prompt,\n",
        "                                 image_path)\n",
        "print(image_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erRyCgvzUYej",
        "outputId": "4c0a1db7-6ed8-4148-fa6c-0eafcb7590af"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The image is of a table. On the table is a small bowl of blueberries, two cups of coffee, and five pastries. There is spilled coffee all over the surface of the table. There are also flowers on the table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_description = ga.txt.image(openai_vision_model,\n",
        "                                 0.9,\n",
        "                                 prompt,\n",
        "                                 image_path)\n",
        "print(image_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thueEO0EVwNx",
        "outputId": "d08481ed-0442-4c8e-b319-818b6790a237"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an image of a beautifully presented food setting. It includes several blueberry scones with visible blueberries scattered on top and around them. On the left of the image, there is a small white cup filled with black coffee, and to its right, a smaller bowl containing fresh blueberries. Below the bowl, there's a metal spoon with the text \"LET'S JAM\" imprinted on it, which adds a whimsical touch to the scene. On the right side of the image is a cup of coffee with cream, and the entire setting is accented with a few pink peonies, adding an aesthetic and floral touch. The background has an artistic feel with blue and purple smudges that may be intentional or incidental, resembling a watercolor wash. The overall impression of the photo is one that suggests a leisurely, indulgent moment, possibly a breakfast or a brunch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"This is a risk map of a preditive model of H5N1 outbreak situation in March 2023. Please interrepte in academic standard.\"\n",
        "image_path = \"https://h5n1.gd.edu.kg/images/regional_risk.jpg\""
      ],
      "metadata": {
        "id": "Nxz__O_ibTNG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_description = ga.txt.image(google_vision_model,\n",
        "                                 0.9,\n",
        "                                 prompt,\n",
        "                                 image_path)\n",
        "print(image_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au1GVCMCbinO",
        "outputId": "5611e641-fc2e-4142-b36f-fad7c76b009c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The risk map of the H5N1 outbreak situation in March 2023 shows the predicted risk of an outbreak in each county in the United States. The risk is highest in the Midwest and Northeast regions, with the West and South regions having lower but still significant risk.  The real cases of H5N1 outbreaks are also shown on the map, and they generally correspond to the areas with the highest predicted risk.\n",
            "\n",
            "This map can be used to help public health officials target their efforts to prevent and control the spread of H5N1. By focusing on the areas with the highest risk, they can allocate resources more effectively and help to protect the public from this dangerous disease.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_description = ga.txt.image(openai_vision_model,\n",
        "                                 0.9,\n",
        "                                 prompt,\n",
        "                                 image_path)\n",
        "print(image_description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgrgJN3abkU9",
        "outputId": "d4c84e5b-0d04-46e4-8dfb-7c5d0dc35349"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided image appears to be a composite of risk maps, displaying a predictive model for the H5N1 outbreak across various regions, including the West, South, Midwest, and Northeast regions of the United States, with the inclusion of Alaska and Hawaii in the West region. Each map utilizes a color gradient to represent the Risk Index of H5N1 outbreak, with varying shades of pink indicating the level of risk, which is likely based on a scale from 0 (no risk) to 1.5 (highest observed risk).\n",
            "\n",
            "On each regional map, there are also markers indicating the location and number of \"Real Cases\" of H5N1. These are represented by green circles, with size proportional to the number of cases – the larger the circle, the higher the count of cases. There are additional triangular symbols, possibly indicating another type of data point or relevant information to the H5N1 outbreak model, but without a legend for these symbols, their exact meaning remains unclear.\n",
            "\n",
            "The maps are constructed with a grid overlay, which may be administrative boundaries (like counties), and the variation in the Risk Index can be interpreted to reflect the model's assessment of which areas are more likely to see new cases or outbreaks based on current data.\n",
            "\n",
            "A proper interpretation of the maps would require further information such as the model's parameters, the data sources used (e.g., observed cases, population density, bird migration patterns), and the metrics involved in defining the Risk Index. Moreover, the color gradient for the risk index is not defined beyond 1.5, and it is not clear whether the index's upper limit is 1.5 or if it extends higher with the gradient simply not exhibiting these values due to their absence in the data.\n",
            "\n",
            "Due to the cutoff of information, only careful and general interpretations can be provided without additional context or validation through peer-reviewed research.\n"
          ]
        }
      ]
    }
  ]
}